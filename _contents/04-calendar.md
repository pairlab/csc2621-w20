---
id: calendar
name: Calendar
heading: Calendar
subheading: Calendar&#58;
image: ""
---

|           | Reading                | Topic / Slides
|-----------|------------------------|---------
| **Week 1 Sept 12**   | [Sutton & Barto](https://drive.google.com/file/d/1opPSz5AZ_kVa1uWOdOiveNiBFiEOHjkG/view), Ch 1       | Introduction <br/> [pdf slides](/assets/slides/lec1.pdf) 
| | |
| **Week 2 Sept 19**   | [Sutton & Barto](https://drive.google.com/file/d/1opPSz5AZ_kVa1uWOdOiveNiBFiEOHjkG/view), Ch 2-4     | Multi-Armed Bandits, MDPs, Dynamic Programming  <br/> [pdf slides](/assets/slides/lec2.pdf)
| | |
| **Week 3 Sept 26** | [Sutton & Barto](https://drive.google.com/file/d/1opPSz5AZ_kVa1uWOdOiveNiBFiEOHjkG/view), Ch 5-7 | Monte-Carlo and Temporal Difference Learning <br/> [pdf slides](/assets/slides/lec3.pdf) 
|-----------|------------------------|---------
|  | **Value Function Approximation** |  
|-----------|------------------------|---------
| | [Baird. Residual algorithm: Reinforcement Learning with Function Approximation](http://www.leemon.com/papers/1995b.pdf) | 
|-----------|------------------------|---------
| | [Tsitsiklis, Roy. An Analysis of Temporal-Difference Learning with Function Approximation](http://web.mit.edu/jnt/www/Papers/J063-97-bvr-td.pdf) |  
|-----------|------------------------|---------
| | [Tesauro. Temporal Difference Learning and TD-Gammon](http://enzodesiage.com/wp-content/uploads/2017/08/tesauro-tdgammon-1995.pdf) |  Karthik Raja
|-----------|------------------------|---------
| | [Riedmiller. Neural Fitted Q Iteration](http://ml.informatik.uni-freiburg.de/former/_media/publications/rieecml05.pdf) |  Oliver Limoyo
|-----------|------------------------|---------
| | [Minh, et al. Human-level control through deep reinforcement learning](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf) |  Hyunmin Lee
| | |  
| **Week 4 Oct 3** | **Monte-Carlo Planning** | 
|-----------|------------------------|---------
| | [Column, Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search](https://hal.inria.fr/inria-00116992/document) | Bret Nestor
|-----------|------------------------|---------
| | [Kocsis, Szepesvari, Bandit based Monte-Carlo Planninga](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.102.1296) | Ranjani Murali  
|-----------|------------------------|---------
| | [Gelly, Silver. Combining Online and Offline Knowledge in UCT](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Applications_files/combining_uct.pdf) | Alberto Camacho
|-----------|------------------------|---------
| | [Silver, et. al. Temporal-Difference Search in Computer Go](https://link.springer.com/content/pdf/10.1007%2Fs10994-012-5280-0.pdf) | Jesse Bettencourt
|-----------|------------------------|---------
| | [Silver, et. al. Mastering the game of Go with deep neural networks and tree search](https://deepmind.com/documents/119/agz_unformatted_nature.pdf) | Will Grathwohl
|-----------|------------------------|---------
| | **Policy Search** | 
|-----------|------------------------|---------
| | [Konda, Tsitsiklis. Actor-Critic Algorithms](https://papers.nips.cc/paper/1786-actor-critic-algorithms.pdf) | Xiaohui Zeng
|-----------|------------------------|---------
| | [Sutton, et. al. Policy Gradient Methods for Reinforcement Learning with Function Approximation](https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf) | Lan Xiao
|-----------|------------------------|---------
| | [Baxter, Bartlett. Infinite-Horizon Policy-Gradient Estimation](https://arxiv.org/pdf/1106.0665.pdf) | 
|-----------|------------------------|---------
| | [Sutton, et. al. Comparing Policy-Gradient Algorithms](https://pdfs.semanticscholar.org/beef/9a0f27e4ca54eb5c5311f6ac90d90fa88f12.pdf) | Angeline Yasodhara
|-----------|------------------------|---------
| | [Tang, Abbeel. On a Connection between Importance Sampling and the Likelihood Ratio Policy Gradient](http://rll.berkeley.edu/~jietang/pubs/nips10_Tang.pdf) | Amanjit Singh Kainth
|                    |               |  
| **Week 5 Oct 10**  | **Policy Search Cont.** |  
|-----------|------------------------|---------
| | [Minh, et. al. Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783.pdf) | Alex Adam
|-----------|------------------------|---------
| | [Grudic, et. al. Refining Autonomous Robot Controllers Using Reinforcement Learning](ftp://swanson.seas.upenn.edu/pub/kumar/papers/2003/robRL.pdf) | Jonathan Lorraine
|-----------|------------------------|---------
| | [Hafner, Riedmiller. Reinforcement learning in feedback control](https://link.springer.com/article/10.1007/s10994-011-5235-x) | Srinivasan
|-----------|------------------------|---------
| | [Silver, et. al. Deterministic Policy Gradient Algorithms](http://proceedings.mlr.press/v32/silver14.pdf) | Silviu Pitis
|-----------|------------------------|---------
| | [Lillicrap, et. al. Continuous control with deep reinforcement learning](https://arxiv.org/pdf/1509.02971.pdf)  | Sergio Casas
|-----------|------------------------|---------
| | **Hierarchical RL** |
|-----------|------------------------|---------
| | [Parr, Russell. Reinforcement Learning with Hierarchies of Machines](https://people.eecs.berkeley.edu/~russell/classes/cs294/f05/papers/parr+russell-1998.pdf) | Bryan Chan
|-----------|------------------------|---------
| | [Barto, et. al. Intrinsically Motivated Learning of Hierarchical Collections of Skills](http://www-anw.cs.umass.edu/~barto/courses/cs687/barto_sc_ICDL04.pdf)  | Zihang Fu
|-----------|------------------------|---------
| | [Sutton, et. al. Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning](http://www-anw.cs.umass.edu/~barto/courses/cs687/Sutton-Precup-Singh-AIJ99.pdf) | Reid McIlroy-Young
|-----------|------------------------|---------
| | [Dietterich. Hierarchical Reinforcement Learning with the MAXQ Value Function](https://arxiv.org/abs/cs/9905014) |
|-----------|------------------------|---------
| | [Guestrin, et. al. Coordinated Reinforcement Learning](https://people.eecs.berkeley.edu/~russell/classes/cs294/f05/papers/guestrin+al-2002.pdf) | Safwan Hossain
|                    |               |  
| **<span style="color:#b32425">Project proposal due (Oct 14)</span>**            |        |
|                   |               |  
| **Week 6 Oct 17**  | **Exploration, Intrinsic Motivation, Curiosity** |
|-----------|------------------------|---------
| | [Schmidhuber. Curious model-building control systems.](ftp://ftp.idsia.ch/pub/juergen/curioussingapore.pdf) | S. Vineeth Bhaskara
|-----------|------------------------|---------
| | [Mohamed, Rezende. Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning](https://arxiv.org/pdf/1509.08731) | Yingying Fu
|-----------|------------------------|---------
| | [Stadie, et. al. Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models](https://arxiv.org/abs/1507.00814)	| Zeqi Li
|-----------|------------------------|---------
| | [Pathak, et. al. Curiosity-driven Exploration by Self-supervised Prediction](https://arxiv.org/pdf/1705.05363) | Harris Chan
|-----------|------------------------|---------
| | [Houthooft, et. al. VIME: Variational Information Maximizing Exploration](https://arxiv.org/pdf/1605.09674.pdf) | Zahra Shekarchi
|-----------|------------------------|---------
| | **Model-based RL** |	
|-----------|------------------------|---------
| | [Levine, Koltun, Guided Policy Search](https://graphics.stanford.edu/projects/gpspaper/gps_full.pdf) | Shengyang Sun
|-----------|------------------------|---------
| | [Nagabandi, et. al. Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning](https://arxiv.org/pdf/1708.02596.pdf) | Yin-Hung Chen
|-----------|------------------------|---------
| | [Chua, et. al. Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models](https://arxiv.org/pdf/1805.12114.pdf) | Paul Briggs
|-----------|------------------------|---------
| | [Botev, et. al. The Cross-Entropy Method for Optimization](https://people.smp.uq.edu.au/DirkKroese/ps/CEopt.pdf) | Haicheng Wang
|-----------|------------------------|---------
| | [Sutton. Dyna, an Integrated Architecture for Learning, Planning, and Reacting](http://papersdb.cs.ualberta.ca/~papersdb/uploaded_files/paper_p160-sutton.pdf.stjohn) + [Kurutach, et. al. Model-Ensemble Trust-Region Policy Optimization](https://arxiv.org/abs/1802.10592) |Eric Langlois
|-----------|------------------------|---------
| | [Ha, Schmidhuber. World Models](https://arxiv.org/abs/1803.10122) | Farzaneh Mahdisoltani
|                    |               |  
| **Week 7 Oct 24**  | **Energy-based control/inference** |
|-----------|------------------------|---------
| | [Haarnoja, et. al. Reinforcement Learning with Deep Energy-Based Policies](https://arxiv.org/abs/1702.08165)
| | [Haarnoja, et. al. Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/abs/1702.08165) | Mohammad Firouzi
| | [Nachum, et. al. Bridging the Gap Between Value and Policy Based Reinforcement Learning](https://arxiv.org/abs/1702.08165) | Kelvin Wong
| | [Ziebart, et. al. Modeling interaction via the principle of maximum causal entropy](http://www.cs.cmu.edu/~bziebart/publications/maximum-causal-entropy.pdf)
| | [Levine. Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review](https://arxiv.org/abs/1805.00909) | Sean Segal
|-----------|------------------------|---------
| | **Inverse RL** |
|-----------|------------------------|---------
| | [Ng, Russell. Algorithms for inverse reinforcement learning](https://ai.stanford.edu/~ang/papers/icml00-irl.pdf) | Simon Suo
| | [Ziebart, et. al. Maximum Entropy Inverse Reinforcement Learning](https://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf) | Elsa Riachi
| | [Finn, et. al. A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models](https://arxiv.org/abs/1611.03852) | Stephane Aroca-Ouellette
| | [Hadfield-Menell, et. al. Inverse Reward Design](https://arxiv.org/abs/1711.02827) | Sneha Desai
|-----------|------------------------|---------
| | **Evolutionary strategy** |
|-----------|------------------------|---------
| | [Brockhoff, et. al. Mirrored Sampling and Sequential Selection for Evolution Strategies](https://hal.inria.fr/inria-00530202v2/document) | Jingcheng Niu
|                    |               |  
| **Week 8 Oct 31**  |               |  
|                    |               |  
| **Week 9 Fall reading week** |     | no class   
|                    |               |  
| **Week 10 Nov 14** |               |  
|                    |               |  
| **Week 11 Nov 21** |               |  
|                    |               |  
| **Week 12 Nov 28** |               |  
|                    |               | Project presentation
| **Week 13 Dec 5**  |               |  
|                    |               | Project presentation
| **<span style="color:#b32425">Final project due (Dec 16)</span>**           |        |
|                    |               |  
