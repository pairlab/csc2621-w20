---
id: calendar
name: Calendar
heading: Calendar
subheading: Calendar&#58;
image: ""
---

This a draft schedule and is subject to change.  

|Schedule           | Broad Area                | Reading List
|-----------|------------------------|---------
|**Week Jan 7** | Course Overview & Intro to RL	|Slides:<br /> [Lecture 1](assets/slides/lec1.pdf),<br />[Presentation Template Slides](assets/slides/template.pptx)<br /><br />Papers:<br />[Human Learning in Atari](https://core.ac.uk/download/pdf/141473125.pdf)|
|**Week Jan 14** | 	Imitation Learning: supervised	|Slides:<br /> [Lecture 2](assets/slides/lec2.pdf), <br />[End To End Learning Slides](assets/slides/lec2_endtoend.pdf),<br />[Behavioural Cloning Slides](assets/slides/lec2_behaviorcloning.pdf)<br /><br /> Overview:<br />[An Invitation To Imitation](https://www.ri.cmu.edu/publications/an-invitation-to-imitation/),<br />[Dagger: A reduction of imitation learning and structured prediction to no-regret online learning](https://arxiv.org/pdf/1011.0686.pdf),<br /> [End to End Learning for Self-Driving Cars](https://arxiv.org/abs/1604.07316),<br /> [Behavioral Cloning from Observation](https://www.ijcai.org/proceedings/2018/0687.pdf)<br /><br />Optional: <br />[ALVINN: An autonomous land vehicle in a neural network](https://papers.nips.cc/paper/95-alvinn-an-autonomous-land-vehicle-in-a-neural-network.pdf),<br />[ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst](https://arxiv.org/abs/1812.03079),<br />[Apprenticeship Learning via Inverse Reinforcement Learning](https://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf)|
|**Week Jan 21** | 	Policy Gradients	|[Policy Gradient Methods for Reinforcement Learning with Function Approximation](https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf),<br />[Trust region policy optimization: deep RL with natural policy gradient and adaptive step size](https://arxiv.org/pdf/1502.05477) (TRPO),<br /> [Continuous control with deep reinforcement learning](https://arxiv.org/abs/1509.02971) (DDPG), <br /> [Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines](https://arxiv.org/pdf/1803.07246.pdf)<br /><br />Optional:<br />SB Ch: 13, <br /> [Reinforcement learning of motor skills with policy gradients](https://www.sciencedirect.com/science/article/pii/S0893608008000701)|
|**Week Jan 28** | 	Actor-Critic Methods+ Value Based methods	|[Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/abs/1602.01783),<br />[Soft Actor-Critic Algorithms and Applications](https://arxiv.org/abs/1812.05905),<br />[IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures](https://arxiv.org/abs/1802.01561),<br />[High-confidence error estimates for learned value functions](https://arxiv.org/abs/1808.09127)<br /><br />Optional:<br />SB Ch: 13,<br />[Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/abs/1801.01290)
|
|**Week Jan 28** | 	(before class)	| **<span style="color:#b32425">Project Proposal Due</span>**|
|**Week Feb 4** | Q-Value based RL|	[Playing Atari with Deep Reinforcement Learning Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/abs/1509.06461),<br />[Rainbow - Combining Improvements in Deep Reinforcement Learning](https://arxiv.org/abs/1710.02298)|
|**Week Feb 11** | 	Distributional RL	|[A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887.pdf)|
|**Week Feb 18** | 	Model-Based RL	|[Intro to ILQR](https://homes.cs.washington.edu/~todorov/papers/LiICINCO04.pdf) (Animesh),<br />[Benchmarking Model-Based Reinforcement Learning](https://arxiv.org/abs/1907.02057),<br />[Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models](https://arxiv.org/abs/1805.12114) (PETS),<br /> [Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees](https://arxiv.org/abs/1807.03858) (SLBO),<br /> [Dream to Control: Learning Behaviors by Latent Imagination](https://arxiv.org/abs/1912.01603)<br /><br />Optional:<br />[PlaNet Learning Latent Dynamics for Planning from Pixels](https://arxiv.org/abs/1811.04551),<br />[World Models](https://worldmodels.github.io/),<br />[PILCO: Probabilistic Inference for Learning COntrol](http://mlg.eng.cam.ac.uk/carl/pilco/)|
|**Week Feb 25** | 	(before class)	|**<span style="color:#b32425">Mid-Term Project Report Due</span>**|
|**Week Feb 25** | 	Imitation: Inverse RL	|[Generative Adversarial Imitation Learning](https://arxiv.org/abs/1606.03476),<br />[Maximum Entropy Inverse Reinforcement Learning](https://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf),<br />[Provably Efficient Imitation Learning from Observation Alone](https://arxiv.org/abs/1905.10948)<br /><br />Optional:<br />[Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation](https://arxiv.org/abs/1707.03374)|
|**Week Feb 28** | 	Friday 9am	| **<span style="color:#b32425">Take Home Midterm (24 hours to turn-in)</span>**|
|**Week Mar 3** | Exploration in RL	|[Deep Exploration via Bootstrapped DQN](https://arxiv.org/abs/1602.04621),<br />[Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models](https://arxiv.org/abs/1507.00814),<br /> [Large-Scale Study of Curiosity-Driven Learning Episodic Curiosity through Reachability](https://arxiv.org/abs/1808.04355)|
|**Week Mar 10** | 	Bayesian RL	|[Bayesian Reinforcement Learning: A Survey](https://arxiv.org/abs/1609.04436),<br />[VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning](https://arxiv.org/abs/1910.08348)|
|**Week Mar 17** | 	Hierarchical RL	||
|**Week Mar 24** | 	Project Presentation	||
|**Week Mar 31** | 	Project Presentation	||
|**Week Apr 7** | [Buffer]	||
|**Week Apr 7** | Tues 11:59 pm	|**<span style="color:#b32425">Final Project Report Due</span>**|
